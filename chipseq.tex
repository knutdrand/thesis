Chip-seq is an experiment designed to elucidate where a transcription factor binds. Immunoprecipitation is used to isolate small fragments of DNA which have the transcription factor bound to them.
Ends of these framgents are then sequencesed yielding reads that in general are assumed to be in the vincinity of a binding site. In order to find from this where the transcription factor was bound bioinformatics pipelines are needed.
This is in general consists of mapping the reads to a reference genome, and performing \emph{peak calling} on the coordinates of the mapped reads.
Peak calling is required to estimate from the mapped reads,
only known to tend to be in the vicinity of a binding site, where the binding site is.
The input to peak calling is a set of directed intervals and the output is generally either a set of positions, or a set of undirected intervals that denote the predicted binding sites. 
\[PC: \intervals_G \rightarrow \intervals^+_G\] 
A range of methods for performing peak calling exists~\cite{macs2, SPP, peakcallreview}.
In the following is described the algorithms used by MACS2 and the adaptions to those algorithms used by Graph Peak Caller descirbed in Paper 3 and Paper 4.

\subsection{MACS2}
The input is a set of intervals $\set{(s_k, e_k, d_k)}$. The first step is to count how many extended reads cover each position of the reference genome, where each interval is extended to a length equaling a previously estimated fragment length $f$. I.e for each position $i$ we want to find the count
$$P(i)= \size{\buildset{k}{d_k=1 \wedge s_k \leq i < s_k+f} \cup \buildset{k}{d_k=-1 \wedge e_k-f \leq i < e_k}}$$
  The pileup function $P$ is represented sparsely by a set of indices $\set{s_k}$ and values $\set{v_k}$ such that $$\forall{k}\forall{j\in\set{s_k, s_k+1},,,s_{k+1}}(P(j) = v_k)$$
  the indices and values are found algorithmically as
  \begin{lstlisting}
def count_extended(intervals, f):    
    starts = [s if d==1 else e-f for s, e, d in intervals]
    ends = [e if d==1 else s+f for s, e, d in intervals]
    changes = starts+ends
    args = argsort(changes)
    codes = [1 if arg<=len(starts) else -1 for arg in args]
    s = changes[args]
    v = cumsum(codes)
    return s, v
  \end{lstlisting}
  Which is done in $O(n \log n)$ time. The counts for each position is compared with a background track which represents a local average of reads. This is generated by using a large extension length and dividing the pileup values by the extension size.
  \code{s, v = count_extended(control_intervals, E)/E; v/=E}.
  Assuming that each count $P(i)$ are Poisson distributed as $P_i ~ Poisson(\lambda_i)$, a null hypothesis of $H_0^i: \lambda_i=C(i), H_a^i:\lambda_i>C(i)$ is made for each position and a p-value calcluated: $p_i = P(P_i>=P(i))$ \TODO{too many ps}. Too adjust for multiple testing, a final set of q values is calculated as $q_i = p_iN_i$ where $N_i = \size{\buildset{k\in\set{1, 2,,,\size{G}}}{p_k\leq p_i}}$. The q values are thresholded on a given significance level $\alpha$ so we get $T(i) = q_i\leq \alpha$. 
  \begin{lstlisting}
def get_p_values(pileup, background):
    indices = pileup.indices + background.indices
    indices.sort()
    pileup_values = pileup.values[search_sorted(indices, pileup.indices)]
    background_values = background.values[search_sorted(indices, background.indices)]
    p_values = poisson.sf(pileup_values, background_values)
    return Pileup(indices, p_values)
  \end{lstlisting}
Which is done in $O(n)$ time.
\begin{lstlisting}
def get_q_values(p_values):
    counts = diff(p_values.indices)
    args = argsort(p_values.values)
    values, idxs = unique(p_values, return_index=True)
    N = cumsum(counts[args])[idxs]
    q_values = N*values
    all_q_values = zeros_like(p_values.values)
    all_q_values[idxs] = diff(q_values)
    all_q_values = cumsum(all_q_values)
    restored = zeros_like(all_q_values)
    restored[args] = all_q_values
    return Pileup(p_values.indices, restored)
  \end{lstlisting}
  The thresholded values are obtained simply by \code{Pileup(q_values.indices, q_values.values>alpha)}.

The final peaks are called in two steps from the thresholded values. First, joining peak intervals that are separated by less than the estimated read length, and secondly removing peaks that are shorter than the estimated fragment length $f$. Both steps can be made using the same function.
\begin{lstlisting}
def remove_small(indices, size):
    indices = indices.reshape((-1, 2))
    lengths = indices[:, 1]-indices[:, 0]
    big_enough = lengths>=size
    return indices[big_enough].ravel()

peaks = r_[indices[0], remove_small(indices[1:-1], read_length), indices[-1]]
peaks = remove_small(peaks, fragment_length)
\end{lstlisting}


% 
% 
% 
% 
%  of positions in the graph.
% rd$ by \code{node_offsets[v]+o}. The inverse conversion of a coordinate $i \in \linearcoord$ is done by \code{v=searchsorted(node_offset, i); o = i-node_offsets[v])}
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% Í„onger than the estimated fragment length.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
