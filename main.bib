@article{ngs,
  title={Ten years of next-generation sequencing technology},
  author={Van Dijk, Erwin L and Auger, H{\'e}l{\`e}ne and Jaszczyszyn, Yan and Thermes, Claude},
  journal={Trends in genetics},
  volume={30},
  number={9},
  pages={418--426},
  year={2014},
  publisher={Elsevier}
}

@article{reversiblechain,
  title={DNA polymerase fluorescent substrates with reversible 3'-tags},
  author={Canard, Bruno and Sarfati, Robert S},
  journal={Gene},
  volume={148},
  number={1},
  pages={1--6},
  year={1994},
  publisher={Elsevier}
}

@journal{7bridges2,
  title={Fast and accurate genomic analyses using genome graphs},
  author={Rakocevic, Goran and Semenyuk, Vladimir and Lee, Wan-Ping and Spencer, James and Browning, John and Johnson, Ivan J and Arsenijevic, Vladan and Nadj, Jelena and Ghose, Kaushik and Suciu, Maria C and others},
  year={2019},
  institution={Nature Publishing Group}
}
@article{7bridges,
  title={Fast and accurate genomic analyses using genome graphs},
  author={Rakocevic, Goran and Semenyuk, Vladimir and Lee, Wan-Ping and Spencer, James and Browning, John and Johnson, Ivan J and Arsenijevic, Vladan and Nadj, Jelena and Ghose, Kaushik and Suciu, Maria C and others},
  year={2019},
  journal={Nature Genetics},
  volume={51},
  number={2},
  pages={354--362},
  publisher={Nature Publishing Group}
}


@article{hbexample,
  title={DNase hypersensitive sites and association with multiple sclerosis},
  author={Disanto, Giulio and Kjetil Sandve, Geir and Ricigliano, Vito AG and Pakpoor, Julia and Berlanga-Taylor, Antonio J and Handel, Adam E and Kuhle, Jens and Holden, Lars and Watson, Corey T and Giovannoni, Gavin and others},
  journal={Human molecular genetics},
  volume={23},
  number={4},
  pages={942--948},
  year={2013},
  publisher={Oxford University Press}
}

@book{molbio,
publisher = {Garland Science},
isbn = {9780815344322},
year = {2015},
title = {Molecular biology of the cell},
author = {Alberts, Bruce and Johnson, Alexander D and Lewis, Julian and Morgan David and Raff,  Martin and Roberts, Keith and Walter, Peter},
edition = {6th},
language = {eng},
address = {New York},
}

@article{roadmap,
  title={The NIH roadmap epigenomics mapping consortium},
  author={Bernstein, Bradley E and Stamatoyannopoulos, John A and Costello, Joseph F and Ren, Bing and Milosavljevic, Aleksandar and Meissner, Alexander and Kellis, Manolis and Marra, Marco A and Beaudet, Arthur L and Ecker, Joseph R and others},
  journal={Nature biotechnology},
  volume={28},
  number={10},
  pages={1045--1048},
  year={2010},
  publisher={Nature Publishing Group}
}

@article{gwas,
  title={Five years of GWAS discovery},
  author={Visscher, Peter M and Brown, Matthew A and McCarthy, Mark I and Yang, Jian},
  journal={The American Journal of Human Genetics},
  volume={90},
  number={1},
  pages={7--24},
  year={2012},
  publisher={Elsevier}
}

@article{genomegraphs,
	title = {Genome graphs and the evolution of genome inference},
	volume = {27},
	issn = {1088-9051, 1549-5469},
	doi = {10.1101/gr.214155.116},
	abstract = {The human reference genome is part of the foundation of modern human biology and a monumental scientific achievement. However, because it excludes a great deal of common human variation, it introduces a pervasive reference bias into the field of human genomics. To reduce this bias, it makes sense to draw on representative collections of human genomes, brought together into reference cohorts. There are a number of techniques to represent and organize data gleaned from these cohorts, many using ideas implicitly or explicitly borrowed from graph-based models. Here, we survey various projects underway to build and apply these graph-based structures—which we collectively refer to as genome graphs—and discuss the improvements in read mapping, variant calling, and haplotype determination that genome graphs are expected to produce.},
	language = {en},
	number = {5},
	journal = {Genome Research},
	author = {Paten, Benedict and Novak, Adam M. and Eizenga, Jordan M. and Garrison, Erik},
	month = may,
	year = {2017},
	pmid = {28360232},
	pages = {665--676},
	file = {Full Text PDF:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/J9BFQ7BJ/Paten et al. - 2017 - Genome graphs and the evolution of genome inferenc.pdf:application/pdf;Snapshot:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/F74WB2LM/665.html:text/html}
}

@article{drosophila,
	title = {{FlyBase}: introduction of the {Drosophila} melanogaster {Release} 6 reference genome assembly and large-scale migration of genome annotations},
	volume = {43},
	issn = {0305-1048},
	shorttitle = {{FlyBase}},
	doi = {10.1093/nar/gku1099},
	abstract = {Abstract.  Release 6, the latest reference genome assembly of the fruit fly Drosophila melanogaster, was released by the Berkeley Drosophila Genome Project in 2},
	language = {en},
	number = {D1},
	journal = {Nucleic Acids Research},
	author = {dos Santos, Gilberto and Schroeder, Andrew J. and Goodman, Joshua L. and Strelets, Victor B. and Crosby, Madeline A. and Thurmond, Jim and Emmert, David B. and Gelbart, William M.},
	month = jan,
	year = {2015},
	pages = {D690--D697},
	file = {Full Text PDF:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/XNXZIJI7/dos Santos et al. - 2015 - FlyBase introduction of the Drosophila melanogast.pdf:application/pdf;Snapshot:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/6EG5CUTW/dos Santos et al. - 2015 - FlyBase introduction of the Drosophila melanogast.html:text/html}
}

@article{bwtsw,
	title = {Compressed indexing and local alignment of {DNA}},
	volume = {24},
	issn = {1367-4803},
	doi = {10.1093/bioinformatics/btn032},
	abstract = {Abstract.  Motivation: Recent experimental studies on compressed indexes (BWT, CSA, FM-index) have confirmed their practicality for indexing very long strings s},
	language = {en},
	number = {6},
	journal = {Bioinformatics},
	author = {Lam, T. W. and Sung, W. K. and Tam, S. L. and Wong, C. K. and Yiu, S. M.},
	month = mar,
	year = {2008},
	pages = {791--797},
	file = {Full Text PDF:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/SHNGGT5X/Lam et al. - 2008 - Compressed indexing and local alignment of DNA.pdf:application/pdf;Snapshot:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/VN24F259/Lam et al. - 2008 - Compressed indexing and local alignment of DNA.html:text/html}
}

@article{chipseq2009,
	title = {{ChIP}–seq: advantages and challenges of a maturing technology},
	volume = {10},
	copyright = {2009 Nature Publishing Group},
	issn = {1471-0064},
	shorttitle = {{ChIP}–seq},
	doi = {10.1038/nrg2641},
	abstract = {Chromatin immunoprecipitation followed by sequencing (ChIP–seq) is a technique for genome-wide profiling of DNA-binding proteins, histone modifications or nucleosomes. Owing to the tremendous progress in next-generation sequencing technology, ChIP–seq offers higher resolution, less noise and greater coverage than its array-based predecessor ChIP–chip. With the decreasing cost of sequencing, ChIP–seq has become an indispensable tool for studying gene regulation and epigenetic mechanisms. In this Review, I describe the benefits and challenges in harnessing this technique with an emphasis on issues related to experimental design and data analysis. ChIP–seq experiments generate large quantities of data, and effective computational analysis will be crucial for uncovering biological mechanisms.},
	language = {en},
	number = {10},
	journal = {Nature Reviews Genetics},
	author = {Park, Peter J.},
	month = oct,
	year = {2009},
	pages = {669--680},
	file = {Snapshot:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/VU2DIF7A/Park - 2009 - ChIP–seq advantages and challenges of a maturing .html:text/html}
}

@article{encode,
	title = {The {ENCODE} ({ENCyclopedia} {Of} {DNA} {Elements}) {Project}},
	volume = {306},
	copyright = {American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.1105136},
	abstract = {The ENCyclopedia Of DNA Elements (ENCODE) Project aims to identify all functional elements in the human genome sequence. The pilot phase of the Project is focused on a specified 30 megabases (∼1\%) of the human genome sequence and is organized as an international consortium of computational and laboratory-based scientists working to develop and apply high-throughput approaches for detecting all sequence elements that confer biological function. The results of this pilot phase will guide future efforts to analyze the entire human genome.},
	language = {en},
	number = {5696},
	journal = {Science},
	author = {Consortium, The ENCODE Project},
	month = oct,
	year = {2004},
	pmid = {15499007},
	pages = {636--640},
	file = {Full Text PDF:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/CCQ9B5WB/Consortium - 2004 - The ENCODE (ENCyclopedia Of DNA Elements) Project.pdf:application/pdf;Snapshot:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/7XJUFQVI/Consortium - 2004 - The ENCODE (ENCyclopedia Of DNA Elements) Project.html:text/html}
}
@article{indexcomplexity,
  title={On the Complexity of Exact Pattern Matching in Graphs: Binary Strings and Bounded Degree},
  author={Equi, Massimo and Grossi, Roberto and M{\"a}kinen, Veli},
  journal={arXiv preprint arXiv:1901.05264},
  year={2019}
}
@article{pacbio,
	series = {{SI}: {Metagenomics} of {Marine} {Environments}},
	title = {{PacBio} {Sequencing} and {Its} {Applications}},
	volume = {13},
	issn = {1672-0229},
	doi = {10.1016/j.gpb.2015.08.002},
	abstract = {Single-molecule, real-time sequencing developed by Pacific BioSciences offers longer read lengths than the second-generation sequencing (SGS) technologies, making it well-suited for unsolved problems in genome, transcriptome, and epigenetics research. The highly-contiguous de novo assemblies using PacBio sequencing can close gaps in current reference assemblies and characterize structural variation (SV) in personal genomes. With longer reads, we can sequence through extended repetitive regions and detect mutations, many of which are associated with diseases. Moreover, PacBio transcriptome sequencing is advantageous for the identification of gene isoforms and facilitates reliable discoveries of novel genes and novel isoforms of annotated genes, due to its ability to sequence full-length transcripts or fragments with significant lengths. Additionally, PacBio’s sequencing technique provides information that is useful for the direct detection of base modifications, such as methylation. In addition to using PacBio sequencing alone, many hybrid sequencing strategies have been developed to make use of more accurate short reads in conjunction with PacBio long reads. In general, hybrid sequencing strategies are more affordable and scalable especially for small-size laboratories than using PacBio Sequencing alone. The advent of PacBio sequencing has made available much information that could not be obtained via SGS alone.},
	number = {5},
	journal = {Genomics, Proteomics \& Bioinformatics},
	author = {Rhoads, Anthony and Au, Kin Fai},
	month = oct,
	year = {2015},
	keywords = {assembly, Gene isoform detection, Hybrid sequencing, Methylation, Third-generation sequencing},
	pages = {278--289},
	file = {ScienceDirect Full Text PDF:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/53Q3ZPMI/Rhoads and Au - 2015 - PacBio Sequencing and Its Applications.pdf:application/pdf;ScienceDirect Snapshot:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/MF5HKAZ2/Rhoads and Au - 2015 - PacBio Sequencing and Its Applications.html:text/html}
}

@misc{changereference,
	title = {Is it time to change the reference genome? {\textbar} {bioRxiv}},
}

@misc{hybridindex,
	title = {Fully-sensitive {Seed} {Finding} in {Sequence} {Graphs} {Using} a {Hybrid} {Index} {\textbar} {bioRxiv}},
}

@article{mapping,
	title = {Short {Read} {Mapping}: {An} {Algorithmic} {Tour}},
	volume = {105},
	issn = {0018-9219},
	shorttitle = {Short {Read} {Mapping}},
	doi = {10.1109/JPROC.2015.2455551},
	abstract = {Ultra-high-throughput next-generation sequencing (NGS) technology allows us to determine the sequence of nucleotides of many millions of DNA molecules in parallel. Accompanied by a dramatic reduction in cost since its introduction in 2004, NGS technology has provided a new way of addressing a wide range of biological and biomedical questions, from the study of human genetic disease to the analysis of gene expression, protein-DNA interactions, and patterns of DNA methylation. The data generated by NGS instruments comprise huge numbers of very short DNA sequences, or ’reads’, that carry little information by themselves. These reads therefore have to be pieced together by well-engineered algorithms to reconstruct biologically meaningful measurments, such as the level of expression of a gene. To solve this complex, high-dimensional puzzle, reads must be mapped back to a reference genome to determine their origin Due to sequencing errors and to genuine differences between the reference genome and the individual being sequenced, this mapping process must be tolerant of mismatches, insertions, and deletions. Although optimal alignment algorithms to solve this problem have long been available, the practical requirements of aligning hundreds of millions of short reads to the 3 billion base pair long human genome have stimulated the development of new, more efficient methods, which today are used routinely throughout the world for the analysis of NGS data.},
	number = {3},
	journal = {Proceedings of the IEEE. Institute of Electrical and Electronics Engineers},
	author = {Canzar, Stefan and Salzberg, Steven L.},
	month = mar,
	year = {2017},
	pmid = {28502990},
	pmcid = {PMC5425171},
	pages = {436--458},
	file = {PubMed Central Full Text PDF:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/V3PEU6CT/Canzar and Salzberg - 2017 - Short Read Mapping An Algorithmic Tour.pdf:application/pdf}
}

@article{music,
	title = {{MUSIC}: identification of enriched regions in {ChIP}-{Seq} experiments using a mappability-corrected multiscale signal processing framework},
	volume = {15},
	issn = {1465-6906},
	shorttitle = {{MUSIC}},
	doi = {10.1186/s13059-014-0474-3},
	abstract = {We present MUSIC, a signal processing approach for identification of enriched regions in ChIP-Seq data, available at music.gersteinlab.org. MUSIC first filters the ChIP-Seq read-depth signal for systematic noise from non-uniform mappability, which fragments enriched regions. Then it performs a multiscale decomposition, using median filtering, identifying enriched regions at multiple length scales. This is useful given the wide range of scales probed in ChIP-Seq assays. MUSIC performs favorably in terms of accuracy and reproducibility compared with other methods. In particular, analysis of RNA polymerase II data reveals a clear distinction between the stalled and elongating forms of the polymerase.},
	number = {10},
	journal = {Genome Biology},
	author = {Harmanci, Arif and Rozowsky, Joel and Gerstein, Mark},
	year = {2014},
	pmid = {25292436},
	pmcid = {PMC4234855},
	file = {PubMed Central Full Text PDF:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/8QAWQN6E/Harmanci et al. - 2014 - MUSIC identification of enriched regions in ChIP-.pdf:application/pdf}
}

@article{SPP,
	title = {Design and analysis of {ChIP}-seq experiments for {DNA}-binding proteins},
	volume = {26},
	copyright = {2008 Nature Publishing Group},
	issn = {1546-1696},
	doi = {10.1038/nbt.1508},
	abstract = {Recent progress in massively parallel sequencing platforms has enabled genome-wide characterization of DNA-associated proteins using the combination of chromatin immunoprecipitation and sequencing (ChIP-seq). Although a variety of methods exist for analysis of the established alternative ChIP microarray (ChIP-chip), few approaches have been described for processing ChIP-seq data. To fill this gap, we propose an analysis pipeline specifically designed to detect protein-binding positions with high accuracy. Using previously reported data sets for three transcription factors, we illustrate methods for improving tag alignment and correcting for background signals. We compare the sensitivity and spatial precision of three peak detection algorithms with published methods, demonstrating gains in spatial precision when an asymmetric distribution of tags on positive and negative strands is considered. We also analyze the relationship between the depth of sequencing and characteristics of the detected binding positions, and provide a method for estimating the sequencing depth necessary for a desired coverage of protein binding sites.},
	language = {en},
	number = {12},
	journal = {Nature Biotechnology},
	author = {Kharchenko, Peter V. and Tolstorukov, Michael Y. and Park, Peter J.},
	month = dec,
	year = {2008},
	pages = {1351--1359},
	file = {Snapshot:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/6IKQ4Z6A/Kharchenko et al. - 2008 - Design and analysis of ChIP-seq experiments for DN.html:text/html}
}

@article{hiddenDomains,
	title = {Detecting broad domains and narrow peaks in {ChIP}-seq data with {hiddenDomains}},
	volume = {17},
	issn = {1471-2105},
	doi = {10.1186/s12859-016-0991-z},
	abstract = {Background
Correctly identifying genomic regions enriched with histone modifications and transcription factors is key to understanding their regulatory and developmental roles. Conceptually, these regions are divided into two categories, narrow peaks and broad domains, and different algorithms are used to identify each one. Datasets that span these two categories are often analyzed with a single program for peak calling combined with an ad hoc method for domains.

Results
We developed hiddenDomains, which identifies both peaks and domains, and compare it to the leading algorithms using H3K27me3, H3K36me3, GABP, ESR1 and FOXA ChIP-seq datasets. The output from the programs was compared to qPCR-validated enriched and depleted sites, predicted transcription factor binding sites, and highly-transcribed gene bodies. With every method, hiddenDomains, performed as well as, if not better than algorithms dedicated to a specific type of analysis.

Conclusions
hiddenDomains performs as well as the best domain and peak calling algorithms, making it ideal for analyzing ChIP-seq datasets, especially those that contain a mixture of peaks and domains.

Electronic supplementary material
The online version of this article (doi:10.1186/s12859-016-0991-z) contains supplementary material, which is available to authorized users.},
	journal = {BMC Bioinformatics},
	author = {Starmer, Joshua and Magnuson, Terry},
	month = mar,
	year = {2016},
	pmid = {27009150},
	pmcid = {PMC4806451},
	file = {PubMed Central Full Text PDF:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/44EE7SXV/Starmer and Magnuson - 2016 - Detecting broad domains and narrow peaks in ChIP-s.pdf:application/pdf}
}

@article{chipseqbest,
	title = {Features that define the best {ChIP}-seq peak calling algorithms},
	volume = {18},
	issn = {1467-5463},
	doi = {10.1093/bib/bbw035},
	abstract = {Chromatin immunoprecipitation followed by sequencing (ChIP-seq) is an important tool for studying gene regulatory proteins, such as transcription factors and histones. Peak calling is one of the first steps in the analysis of these data. Peak calling consists of two sub-problems: identifying candidate peaks and testing candidate peaks for statistical significance. We surveyed 30 methods and identified 12 features of the two sub-problems that distinguish methods from each other. We picked six methods GEM, MACS2, MUSIC, BCP, Threshold-based method (TM) and ZINBA] that span this feature space and used a combination of 300 simulated ChIP-seq data sets, 3 real data sets and mathematical analyses to identify features of methods that allow some to perform better than the others. We prove that methods that explicitly combine the signals from ChIP and input samples are less powerful than methods that do not. Methods that use windows of different sizes are more powerful than the ones that do not. For statistical testing of candidate peaks, methods that use a Poisson test to rank their candidate peaks are more powerful than those that use a Binomial test. BCP and MACS2 have the best operating characteristics on simulated transcription factor binding data. GEM has the highest fraction of the top 500 peaks containing the binding motif of the immunoprecipitated factor, with 50\% of its peaks within 10 base pairs of a motif. BCP and MUSIC perform best on histone data. These findings provide guidance and rationale for selecting the best peak caller for a given application.},
	number = {3},
	journal = {Briefings in Bioinformatics},
	author = {Thomas, Reuben and Thomas, Sean and Holloway, Alisha K and Pollard, Katherine S},
	month = may,
	year = {2017},
	pmid = {27169896},
	pmcid = {PMC5429005},
	pages = {441--450},
	file = {PubMed Central Full Text PDF:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/GTEJTC3H/Thomas et al. - 2017 - Features that define the best ChIP-seq peak callin.pdf:application/pdf}
}

@article{longmem,
	title = {Long read alignment based on maximal exact match seeds},
	volume = {28},
	issn = {1367-4811},
	doi = {10.1093/bioinformatics/bts414},
	abstract = {MOTIVATION: The explosive growth of next-generation sequencing datasets poses a challenge to the mapping of reads to reference genomes in terms of alignment quality and execution speed. With the continuing progress of high-throughput sequencing technologies, read length is constantly increasing and many existing aligners are becoming inefficient as generated reads grow larger.
RESULTS: We present CUSHAW2, a parallelized, accurate, and memory-efficient long read aligner. Our aligner is based on the seed-and-extend approach and uses maximal exact matches as seeds to find gapped alignments. We have evaluated and compared CUSHAW2 to the three other long read aligners BWA-SW, Bowtie2 and GASSST, by aligning simulated and real datasets to the human genome. The performance evaluation shows that CUSHAW2 is consistently among the highest-ranked aligners in terms of alignment quality for both single-end and paired-end alignment, while demonstrating highly competitive speed. Furthermore, our aligner shows good parallel scalability with respect to the number of CPU threads.
AVAILABILITY: CUSHAW2, written in C++, and all simulated datasets are available at http://cushaw2.sourceforge.net
CONTACT: liuy@uni-mainz.de; bertil.schmidt@uni-mainz.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.},
	language = {eng},
	number = {18},
	journal = {Bioinformatics (Oxford, England)},
	author = {Liu, Yongchao and Schmidt, Bertil},
	month = sep,
	year = {2012},
	pmid = {22962447},
	pmcid = {PMC3436841},
	keywords = {Algorithms, Chromosome Mapping, Genome, Human, Genomics, High-Throughput Nucleotide Sequencing, Humans, Sequence Alignment, Sequence Analysis, DNA, Software},
	pages = {i318--i324}
}

@article{bwalong,
	title = {Fast and accurate long-read alignment with {Burrows}-{Wheeler} transform},
	volume = {26},
	issn = {1367-4811},
	doi = {10.1093/bioinformatics/btp698},
	abstract = {MOTIVATION: Many programs for aligning short sequencing reads to a reference genome have been developed in the last 2 years. Most of them are very efficient for short reads but inefficient or not applicable for reads {\textgreater}200 bp because the algorithms are heavily and specifically tuned for short queries with low sequencing error rate. However, some sequencing platforms already produce longer reads and others are expected to become available soon. For longer reads, hashing-based software such as BLAT and SSAHA2 remain the only choices. Nonetheless, these methods are substantially slower than short-read aligners in terms of aligned bases per unit time.
RESULTS: We designed and implemented a new algorithm, Burrows-Wheeler Aligner's Smith-Waterman Alignment (BWA-SW), to align long sequences up to 1 Mb against a large sequence database (e.g. the human genome) with a few gigabytes of memory. The algorithm is as accurate as SSAHA2, more accurate than BLAT, and is several to tens of times faster than both.
AVAILABILITY: http://bio-bwa.sourceforge.net},
	language = {eng},
	number = {5},
	journal = {Bioinformatics (Oxford, England)},
	author = {Li, Heng and Durbin, Richard},
	month = mar,
	year = {2010},
	pmid = {20080505},
	pmcid = {PMC2828108},
	keywords = {Algorithms, Genome, Human, Genomics, Humans, Sequence Alignment, Sequence Analysis, DNA, Base Sequence},
	pages = {589--595}
}

@article{origsmem,
	title = {Exploring single-sample {SNP} and {INDEL} calling with whole-genome de novo assembly},
	volume = {28},
	issn = {1367-4803},
	doi = {10.1093/bioinformatics/bts280},
	abstract = {Motivation: Eugene Myers in his string graph paper suggested that in a string graph or equivalently a unitig graph, any path spells a valid assembly. As a string/unitig graph also encodes every valid assembly of reads, such a graph, provided that it can be constructed correctly, is in fact a lossless representation of reads. In principle, every analysis based on whole-genome shotgun sequencing (WGS) data, such as SNP and insertion/deletion (INDEL) calling, can also be achieved with unitigs., Results: To explore the feasibility of using de novo assembly in the context of resequencing, we developed a de novo assembler, fermi, that assembles Illumina short reads into unitigs while preserving most of information of the input reads. SNPs and INDELs can be called by mapping the unitigs against a reference genome. By applying the method on 35-fold human resequencing data, we showed that in comparison to the standard pipeline, our approach yields similar accuracy for SNP calling and better results for INDEL calling. It has higher sensitivity than other de novo assembly based methods for variant calling. Our work suggests that variant calling with de novo assembly can be a beneficial complement to the standard variant calling pipeline for whole-genome resequencing. In the methodological aspects, we propose FMD-index for forward–backward extension of DNA sequences, a fast algorithm for finding all super-maximal exact matches and one-pass construction of unitigs from an FMD-index., Availability:
http://github.com/lh3/fermi, Contact:
hengli@broadinstitute.org},
	number = {14},
	journal = {Bioinformatics},
	author = {Li, Heng},
	month = jul,
	year = {2012},
	pmid = {22569178},
	pmcid = {PMC3389770},
	pages = {1838--1844}
}

@article{bwashort,
	title = {Fast and accurate short read alignment with {Burrows}–{Wheeler} transform},
	volume = {25},
	issn = {1367-4803},
	doi = {10.1093/bioinformatics/btp324},
	abstract = {Motivation: The enormous amount of short reads generated by the new DNA sequencing technologies call for the development of fast and accurate read alignment programs. A first generation of hash table-based methods has been developed, including MAQ, which is accurate, feature rich and fast enough to align short reads from a single individual. However, MAQ does not support gapped alignment for single-end reads, which makes it unsuitable for alignment of longer reads where indels may occur frequently. The speed of MAQ is also a concern when the alignment is scaled up to the resequencing of hundreds of individuals., Results: We implemented Burrows-Wheeler Alignment tool (BWA), a new read alignment package that is based on backward search with Burrows–Wheeler Transform (BWT), to efficiently align short sequencing reads against a large reference sequence such as the human genome, allowing mismatches and gaps. BWA supports both base space reads, e.g. from Illumina sequencing machines, and color space reads from AB SOLiD machines. Evaluations on both simulated and real data suggest that BWA is ∼10–20× faster than MAQ, while achieving similar accuracy. In addition, BWA outputs alignment in the new standard SAM (Sequence Alignment/Map) format. Variant calling and other downstream analyses after the alignment can be achieved with the open source SAMtools software package., Availability: http://maq.sourceforge.net, Contact: rd@sanger.ac.uk},
	number = {14},
	journal = {Bioinformatics},
	author = {Li, Heng and Durbin, Richard},
	month = jul,
	year = {2009},
	pmid = {19451168},
	pmcid = {PMC2705234},
	pages = {1754--1760}
}
@article{bwamem,
  title={Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM},
  author={Li, Heng},
  journal={arXiv preprint arXiv:1303.3997},
  year={2013}
}
@article{durbin_efficient_2014,
	title = {Efficient haplotype matching and storage using the positional {Burrows}-{Wheeler} transform ({PBWT})},
	volume = {30},
	issn = {1367-4811},
	doi = {10.1093/bioinformatics/btu014},
	abstract = {MOTIVATION: Over the last few years, methods based on suffix arrays using the Burrows-Wheeler Transform have been widely used for DNA sequence read matching and assembly. These provide very fast search algorithms, linear in the search pattern size, on a highly compressible representation of the dataset being searched. Meanwhile, algorithmic development for genotype data has concentrated on statistical methods for phasing and imputation, based on probabilistic matching to hidden Markov model representations of the reference data, which while powerful are much less computationally efficient. Here a theory of haplotype matching using suffix array ideas is developed, which should scale too much larger datasets than those currently handled by genotype algorithms.
RESULTS: Given M sequences with N bi-allelic variable sites, an O(NM) algorithm to derive a representation of the data based on positional prefix arrays is given, which is termed the positional Burrows-Wheeler transform (PBWT). On large datasets this compresses with run-length encoding by more than a factor of a hundred smaller than using gzip on the raw data. Using this representation a method is given to find all maximal haplotype matches within the set in O(NM) time rather than O(NM(2)) as expected from naive pairwise comparison, and also a fast algorithm, empirically independent of M given sufficient memory for indexes, to find maximal matches between a new sequence and the set. The discussion includes some proposals about how these approaches could be used for imputation and phasing.},
	language = {eng},
	number = {9},
	journal = {Bioinformatics (Oxford, England)},
	author = {Durbin, Richard},
	month = may,
	year = {2014},
	pmid = {24413527},
	pmcid = {PMC3998136},
	keywords = {Algorithms, Genomics, High-Throughput Nucleotide Sequencing, Humans, Sequence Analysis, DNA, Alleles, Genotype, Haplotypes},
	pages = {1266--1272}
}

@article{bwbble,
	title = {Short read alignment with populations of genomes},
	volume = {29},
	issn = {1367-4811},
	doi = {10.1093/bioinformatics/btt215},
	abstract = {SUMMARY: The increasing availability of high-throughput sequencing technologies has led to thousands of human genomes having been sequenced in the past years. Efforts such as the 1000 Genomes Project further add to the availability of human genome variation data. However, to date, there is no method that can map reads of a newly sequenced human genome to a large collection of genomes. Instead, methods rely on aligning reads to a single reference genome. This leads to inherent biases and lower accuracy. To tackle this problem, a new alignment tool BWBBLE is introduced in this article. We (i) introduce a new compressed representation of a collection of genomes, which explicitly tackles the genomic variation observed at every position, and (ii) design a new alignment algorithm based on the Burrows-Wheeler transform that maps short reads from a newly sequenced genome to an arbitrary collection of two or more (up to millions of) genomes with high accuracy and no inherent bias to one specific genome.
AVAILABILITY: http://viq854.github.com/bwbble.},
	language = {eng},
	number = {13},
	journal = {Bioinformatics (Oxford, England)},
	author = {Huang, Lin and Popic, Victoria and Batzoglou, Serafim},
	month = jul,
	year = {2013},
	pmid = {23813006},
	pmcid = {PMC3694645},
	keywords = {Algorithms, Genome, Human, Genomics, High-Throughput Nucleotide Sequencing, Humans, Sequence Alignment, Sequence Analysis, DNA, Software, Genetic Variation},
	pages = {i361--370}
}

@article{na_fm-index_2018,
	title = {{FM}-index of alignment with gaps},
	volume = {710},
	issn = {0304-3975},
	doi = {doi:10.1016/j.tcs.2017.02.020},
	language = {English},
	journal = {Theoretical Computer Science},
	author = {Na, Joong Chae and Kim, Hyunjoon and Min, Seunghwan and Park, Heejin and Lecroq, Thierry and Léonard, Martine and Mouchard, Laurent and Park, Kunsoo},
	month = feb,
	year = {2018},
	pages = {148--157}
}

@inproceedings{succinctdebruijn,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Succinct de {Bruijn} {Graphs}},
	isbn = {978-3-642-33122-0},
	language = {en},
	booktitle = {Algorithms in {Bioinformatics}},
	publisher = {Springer Berlin Heidelberg},
	author = {Bowe, Alexander and Onodera, Taku and Sadakane, Kunihiko and Shibuya, Tetsuo},
	editor = {Raphael, Ben and Tang, Jijun},
	year = {2012},
	keywords = {Edge Label, Incoming Edge, Node Label, Outgoing Edge, Time Complexity},
	pages = {225--235},
	doi = {10.1007/978-3-642-33122-0\_18}
}

@article{gcsa1,
	title = {Indexing {Graphs} for {Path} {Queries} with {Applications} in {Genome} {Research}},
	volume = {11},
	issn = {1545-5963},
	doi = {10.1109/TCBB.2013.2297101},
	abstract = {We propose a generic approach to replace the canonical sequence representation of genomes with graph representations, and study several applications of such extensions. We extend the Burrows-Wheeler transform (BWT) of strings to acyclic directed labeled graphs, to support path queries as an extension to substring searching. We develop, apply, and tailor this technique to a) read alignment on an extended BWT index of a graph representing pan-genome, i.e., reference genome and known variants of it; and b) split-read alignment on an extended BWT index of a splicing graph. Other possible applications include probe/primer design, alignments to assembly graphs, and alignments to phylogenetic tree of partial-order graphs. We report several experiments on the feasibility and applicability of the approach. Especially on highly-polymorphic genome regions our pan-genome index is making a significant improvement in alignment accuracy.},
	number = {2},
	journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
	author = {Siren, J. and Välimäki, N. and Mäkinen, V.},
	month = mar,
	year = {2014},
	keywords = {Genomics, Humans, Sequence Alignment, Sequence Analysis, DNA, acyclic directed labeled graphs, Arrays, Automata, Bioinformatics, Burrows-Wheeler transform, canonical sequence representation, Databases, Genetic, DNA, extended Burrows-Wheeler transform, extended BWT index, generic approach, genome research, genomics, graph indexing, graph representing pan-genome, high-polymorphic genome regions, Indexes, indexing graphs, molecular biophysics, pan-genome index, Pan-genome indexing, partial-order graphs, path queries, phylogenetic tree, Phylogeny, Polymorphism, Single Nucleotide, probe-primer design, read alignment, splicing graph, split-read alignment, Transforms, variation calling, Vectors},
	pages = {375--388},
	file = {IEEE Xplore Abstract Record:/home/knut/.zotero/zotero/l9vrp6df.default/zotero/storage/D8MPWRHU/Siren et al. - 2014 - Indexing Graphs for Path Queries with Applications.html:text/html}
}

@inproceedings{haplotypeaware,
	address = {Dagstuhl, Germany},
	series = {Leibniz {International} {Proceedings} in {Informatics} ({LIPIcs})},
	title = {Haplotype-aware graph indexes},
	volume = {113},
	isbn = {978-3-95977-082-8},
	doi = {10.4230/LIPIcs.WABI.2018.4},
	booktitle = {18th {International} {Workshop} on {Algorithms} in {Bioinformatics} ({WABI} 2018)},
	publisher = {Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik},
	author = {Sirén, Jouni and Garrison, Erik and Novak, Adam M. and Paten, Benedict J. and Durbin, Richard},
	editor = {Parida, Laxmi and Ukkonen, Esko},
	year = {2018},
	keywords = {FM-indexes, haplotypes, variation graphs},
	pages = {4:1--4:13}
}

@article{drosophila,
	title = {{FlyBase}: introduction of the {Drosophila} melanogaster {Release} 6 reference genome assembly and large-scale migration of genome annotations},
	volume = {43},
	issn = {0305-1048},
	shorttitle = {{FlyBase}},
	doi = {10.1093/nar/gku1099},
	abstract = {Abstract. Release 6, the latest reference genome assembly of the fruit fly Drosophila melanogaster, was released by the Berkeley Drosophila Genome Project in 2},
	language = {en},
	number = {D1},
	journal = {Nucleic Acids Research},
	author = {dos Santos, Gilberto and Schroeder, Andrew J. and Goodman, Joshua L. and Strelets, Victor B. and Crosby, Madeline A. and Thurmond, Jim and Emmert, David B. and Gelbart, William M.},
	month = jan,
	year = {2015},
	pages = {D690--D697}
}

@article{vg,
	title = {Variation graph toolkit improves read mapping by representing genetic variation in the reference},
	volume = {36},
	copyright = {2018 Nature Publishing Group},
	issn = {1546-1696},
	doi = {10.1038/nbt.4227},
	abstract = {Reference genomes guide our interpretation of DNA sequence data. However, conventional linear references represent only one version of each locus, ignoring variation in the population. Poor representation of an individual′s genome sequence impacts read mapping and introduces bias. Variation graphs are bidirected DNA sequence graphs that compactly represent genetic variation across a population, including large-scale structural variation such as inversions and duplications1. Previous graph genome software implementations2,3,4 have been limited by scalability or topological constraints. Here we present vg, a toolkit of computational methods for creating, manipulating, and using these structures as references at the scale of the human genome. vg provides an efficient approach to mapping reads onto arbitrary variation graphs using generalized compressed suffix arrays5, with improved accuracy over alignment to a linear reference, and effectively removing reference bias. These capabilities make using variation graphs as references for DNA sequencing practical at a gigabase scale, or at the topological complexity of de novo assemblies.},
	language = {en},
	number = {9},
	journal = {Nature Biotechnology},
	author = {Garrison, Erik and Sirén, Jouni and Novak, Adam M. and Hickey, Glenn and Eizenga, Jordan M. and Dawson, Eric T. and Jones, William and Garg, Shilpa and Markello, Charles and Lin, Michael F. and Paten, Benedict and Durbin, Richard},
	month = sep,
	year = {2018},
	pages = {875--879}
}

@article{sanger,
	title = {{DNA} sequencing with chain-terminating inhibitors},
	volume = {74},
	issn = {0027-8424},
	abstract = {A new method for determining nucleotide sequences in DNA is described. It is similar to the “plus and minus” method [Sanger, F. \& Coulson, A. R. (1975) J. Mol. Biol. 94, 441-448] but makes use of the 2′,3′-dideoxy and arabinonucleoside analogues of the normal deoxynucleoside triphosphates, which act as specific chain-terminating inhibitors of DNA polymerase. The technique has been applied to the DNA of bacteriophage ϕX174 and is more rapid and more accurate than either the plus or the minus method.},
	number = {12},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Sanger, F. and Nicklen, S. and Coulson, A. R.},
	month = dec,
	year = {1977},
	pmid = {271968},
	pmcid = {PMC431765},
	pages = {5463--5467}
}

@article{bowtie1,
	title = {Aligning {Short} {Sequencing} {Reads} with {Bowtie}},
	volume = {32},
	copyright = {© 2010 John Wiley \& Sons, Inc.},
	issn = {1934-340X},
	doi = {10.1002/0471250953.bi1107s32},
	abstract = {This unit shows how to use the Bowtie package to align short sequencing reads, such as those output by second-generation sequencing instruments. It also includes protocols for building a genome index and calling consensus sequences from Bowtie alignments using SAMtools. Curr. Protoc. Bioinform. 32:11.7.1-11.7.14. © 2010 by John Wiley \& Sons, Inc.},
	language = {en},
	number = {1},
	journal = {Current Protocols in Bioinformatics},
	author = {Langmead, Ben},
	year = {2010},
	keywords = {alignment, comparative genomics, genome indexing, mapping, read alignment, read mapping, short reads, software package},
	pages = {11.7.1--11.7.14}
}
@article{bowtie2,
  title={Fast gapped-read alignment with Bowtie 2},
  author={Langmead, Ben and Salzberg, Steven L},
  journal={Nature methods},
  volume={9},
  number={4},
  pages={357--359},
  year={2012},
  publisher={Nature Publishing Group}
}

@article{minimap,
	title = {Minimap and miniasm: fast mapping and de novo assembly for noisy long sequences},
	volume = {32},
	issn = {1367-4803},
	shorttitle = {Minimap and miniasm},
	doi = {10.1093/bioinformatics/btw152},
	abstract = {Abstract. Motivation: Single Molecule Real-Time (SMRT) sequencing technology and Oxford Nanopore technologies (ONT) produce reads over 10 kb in length, which h},
	language = {en},
	number = {14},
	journal = {Bioinformatics},
	author = {Li, Heng},
	month = jul,
	year = {2016},
	pages = {2103--2110}
}

@inproceedings{suffixarray,
	address = {Philadelphia, PA, USA},
	series = {{SODA} '90},
	title = {Suffix {Arrays}: {A} {New} {Method} for {On}-line {String} {Searches}},
	isbn = {978-0-89871-251-3},
	shorttitle = {Suffix {Arrays}},
	booktitle = {Proceedings of the {First} {Annual} {ACM}-{SIAM} {Symposium} on {Discrete} {Algorithms}},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Manber, Udi and Myers, Gene},
	year = {1990},
	pages = {319--327},
	annote = {event-place: San Francisco, California, USA}
}
@inproceedings{BWT,
  title={A block-sorting lossless data compression algorithm},
  author={Burrows, Michael and Wheeler, David J},
  year={1994},
  booktitle={Technical report 124},
  publisher={Digital Equipment Corporation},
  address={Palo Alto, CA.}
}

@inproceedings{fm,
	title = {Opportunistic data structures with applications},
	doi = {10.1109/SFCS.2000.892127},
	abstract = {We address the issue of compressing and indexing data. We devise a data structure whose space occupancy is a function of the entropy of the underlying data set. We call the data structure opportunistic since its space occupancy is decreased when the input is compressible and this space reduction is achieved at no significant slowdown in the query performance. More precisely, its space occupancy is optimal in an information-content sense because text T[1,u] is stored using O(H/sub k/(T))+o(1) bits per input symbol in the worst case, where H/sub k/(T) is the kth order empirical entropy of T (the bound holds for any fixed k). Given an arbitrary string P[1,p], the opportunistic data structure allows to search for the occurrences of P in T in O(p+occlog/sup /spl epsiv//u) time (for any fixed /spl epsiv/{\textbackslash}textgreater0). If data are uncompressible we achieve the best space bound currently known (Grossi and Vitter, 2000); on compressible data our solution improves the succinct suffix array of (Grossi and Vitter, 2000) and the classical suffix tree and suffix array data structures either in space or in query time or both. We also study our opportunistic data structure in a dynamic setting and devise a variant achieving effective search and update time bounds. Finally, we show how to plug our opportunistic data structure into the Glimpse tool (Manber and Wu, 1994). The result is an indexing tool which achieves sublinear space and sublinear query time complexity.},
	booktitle = {Proceedings 41st {Annual} {Symposium} on {Foundations} of {Computer} {Science}},
	author = {Ferragina, P. and Manzini, G.},
	month = nov,
	year = {2000},
	keywords = {computational complexity, Computer science, Costs, data compression, Data engineering, data indexing, data set, data structures, Data structures, database indexing, database theory, entropy, Entropy, Fault tolerance, Glimpse tool, Indexing, opportunistic data structures, Plugs, Postal services, query performance, search, sublinear query time complexity, sublinear space complexity, succinct suffix array, suffix array data structures, suffix tree data structures, Tree data structures},
	pages = {390--398}
}

@article{needlemanwunch,
	title = {A general method applicable to the search for similarities in the amino acid sequence of two proteins},
	volume = {48},
	issn = {0022-2836},
	doi = {10.1016/0022-2836(70)90057-4},
	abstract = {A computer adaptable method for finding similarities in the amino acid sequences of two proteins has been developed. From these findings it is possible to determine whether significant homology exists between the proteins. This information is used to trace their possible evolutionary development. The maximum match is a number dependent upon the similarity of the sequences. One of its definitions is the largest number of amino acids of one protein that can be matched with those of a second protein allowing for all possible interruptions in either of the sequences. While the interruptions give rise to a very large number of comparisons, the method efficiently excludes from consideration those comparisons that cannot contribute to the maximum match. Comparisons are made from the smallest unit of significance, a pair of amino acids, one from each protein. All possible pairs are represented by a two-dimensional array, and all possible comparisons are represented by pathways through the array. For this maximum match only certain of the possible pathways must be evaluated. A numerical value, one in this case, is assigned to every cell in the array representing like amino acids. The maximum match is the largest number that would result from summing the cell values of every pathway.},
	number = {3},
	journal = {Journal of Molecular Biology},
	author = {Needleman, Saul B. and Wunsch, Christian D.},
	month = mar,
	year = {1970},
	pages = {443--453}
}

@article{affine,
	title = {An improved algorithm for matching biological sequences},
	volume = {162},
	issn = {0022-2836},
	doi = {10.1016/0022-2836(82)90398-9},
	abstract = {The algorithm of Waterman et al. (1976) for matching biological sequences was modified under some limitations to be accomplished in essentially MN steps, instead of the M2N steps necessary in the original algorithm. The limitations do not seriously reduce the generality of the original method, and the present method is available for most practical uses. The algorithm can be executed on a small computer with a limited capacity of core memory.},
	number = {3},
	journal = {Journal of Molecular Biology},
	author = {Gotoh, Osamu},
	month = dec,
	year = {1982},
	pages = {705--708}
}

@article{smithwaterman,
	title = {Identification of common molecular subsequences},
	volume = {147},
	issn = {0022-2836},
	doi = {10.1016/0022-2836(81)90087-5},
	number = {1},
	journal = {Journal of Molecular Biology},
	author = {Smith, T. F. and Waterman, M. S.},
	month = mar,
	year = {1981},
	pages = {195--197}
}

 @incollection{nanopore,
 	title = {The potential and challenges of nanopore sequencing},
 	isbn = {978-981-4282-68-0},
 	booktitle = {Nanoscience and {Technology}},
 	publisher = {Co-Published with Macmillan Publishers Ltd, UK},
 	author = {Branton, Daniel and Deamer, David W and Marziali, Andre and Bayley, Hagan and Benner, Steven A and Butler, Thomas and Di Ventra, Massimiliano and Garaj, Slaven and Hibbs, Andrew and Huang, Xiaohua and Jovanovich, Stevan B and Krstic, Predrag S and Lindsay, Stuart and Ling, Xinsheng Sean and Mastrangelo, Carlos H and Meller, Amit and Oliver, John S and Pershin, Yuriy V and Ramsey, J Michael and Riehn, Robert and Soni, Gautam V and Cossa, Vincent Tabard- and Wanunu, Meni and Wiggin, Matthew and Schloss, Jeffery A},
 	month = aug,
 	year = {2009},
 	doi = {10.1142/9789814287005\_0027},
 	pages = {261--268}
 }

@article{macs,
	title = {Model-based {Analysis} of {ChIP}-{Seq} ({MACS})},
	volume = {9},
	issn = {1474-760X},
	doi = {10.1186/gb-2008-9-9-r137},
	abstract = {We present Model-based Analysis of ChIP-Seq data, MACS, which analyzes data generated by short read sequencers such as Solexa's Genome Analyzer. MACS empirically models the shift size of ChIP-Seq tags, and uses it to improve the spatial resolution of predicted binding sites. MACS also uses a dynamic Poisson distribution to effectively capture local biases in the genome, allowing for more robust predictions. MACS compares favorably to existing ChIP-Seq peak-finding algorithms, and is freely available.},
	number = {9},
	journal = {Genome Biology},
	author = {Zhang, Yong and Liu, Tao and Meyer, Clifford A. and Eeckhoute, Jérôme and Johnson, David S. and Bernstein, Bradley E. and Nusbaum, Chad and Myers, Richard M. and Brown, Myles and Li, Wei and Liu, X. Shirley},
	month = sep,
	year = {2008},
	pages = {R137}
}

@incollection{gcsa2,
	series = {Proceedings},
	title = {Indexing {Variation} {Graphs}},
	abstract = {Variation graphs, which represent genetic variation within a population, are replacing sequences as reference genomes. Path indexes are one of the most important tools for working with variation graphs. They generalize text indexes to graphs, allowing one to find the paths matching the query string. We propose using de Bruijn graphs as path indexes, compressing them by merging redundant subgraphs, and encoding them with the Burrows-Wheeler transform. The resulting fast, space-efficient, and versatile index is used in the variation graph toolkit vg.},
	booktitle = {2017 {Proceedings} of the {Ninteenth} {Workshop} on {Algorithm} {Engineering} and {Experiments} ({ALENEX})},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Sirén, J.},
	month = jan,
	year = {2017},
	doi = {10.1137/1.9781611974768.2},
	pages = {13--27}
}

@article{poa2,
	title = {Combining partial order alignment and progressive multiple sequence alignment increases alignment speed and scalability to very large alignment problems},
	volume = {20},
	issn = {1367-4803},
	doi = {10.1093/bioinformatics/bth126},
	abstract = {Abstract. Motivation: Partial order alignment (POA) has been proposed as a new approach to multiple sequence alignment (MSA), which can be combined with existi},
	language = {en},
	number = {10},
	journal = {Bioinformatics},
	author = {Grasso, Catherine and Lee, Christopher},
	month = jul,
	year = {2004},
	pages = {1546--1556}
}

@article{poa,
	title = {Multiple sequence alignment using partial order graphs},
	volume = {18},
	issn = {1367-4803},
	doi = {10.1093/bioinformatics/18.3.452},
	abstract = {Abstract. Motivation: Progressive Multiple Sequence Alignment (MSA) methods depend on reducing an MSA to a linear profile for each alignment step. However,},
	language = {en},
	number = {3},
	journal = {Bioinformatics},
	author = {Lee, Christopher and Grasso, Catherine and Sharlow, Mark F.},
	month = mar,
	year = {2002},
	pages = {452--464}
}

@article{hein,
	title = {A new method that simultaneously aligns and reconstructs ancestral sequences for any number of homologous sequences, when the phylogeny is given.},
	volume = {6},
	issn = {0737-4038},
	doi = {10.1093/oxfordjournals.molbev.a040577},
	abstract = {Abstract. Among the fundamental problems in molecular evolution and in the analysis of homologous sequences are alignment, phylogeny reconstruction, and the re},
	language = {en},
	number = {6},
	journal = {Molecular Biology and Evolution},
	author = {Hein, J.},
	month = nov,
	year = {1989},
	pages = {649--668}
}

@incollection{treealign,
	address = {Totowa, NJ},
	series = {Methods in {Molecular} {Biology}},
	title = {{TreeAlign}},
	isbn = {978-1-59259-512-9},
	abstract = {Several approaches to the multiple alignment problem are conceivable, but virtually all are based on the Parsimony Principle: Choose the history of a set of sequences that minimizes the overall amount of change (insertion-deletions and substitutions/mutations). This formulation was first presented by Sankoff (1) together with a dynamic programming algorithm solving the problem. However, this was so slow that all programs in use have opted for heuristic, but much faster algorithms, and so has TreeAlign. Given the large growth in the data involving sets of homologous sequences, a good solution to this problem has high priority.},
	language = {en},
	booktitle = {Computer {Analysis} of {Sequence} {Data}: {Part} {II}},
	publisher = {Springer New York},
	author = {Hein, Jotun},
	editor = {Griffin, Annette M. and Griffin, Hugh G.},
	year = {1994},
	doi = {10.1385/0-89603-276-0:349},
	keywords = {Alignment Algorithm, Alignment Problem, Ancestral Sequence, Large Deviation Theory, Longe Path},
	pages = {349--364}
}

@article{colocstats,
	title = {Coloc-stats: a unified web interface to perform colocalization analysis of genomic features},
	volume = {46},
	issn = {0305-1048},
	shorttitle = {Coloc-stats},
	doi = {10.1093/nar/gky474},
	abstract = {Abstract. Functional genomics assays produce sets of genomic regions as one of their main outputs. To biologically interpret such region-sets, researchers ofte},
	language = {en},
	number = {W1},
	journal = {Nucleic Acids Research},
	author = {Simovski, Boris and Kanduri, Chakravarthi and Gundersen, Sveinung and Titov, Dmytro and Domanska, Diana and Bock, Christoph and Bossini-Castillo, Lara and Chikina, Maria and Favorov, Alexander and Layer, Ryan M. and Mironov, Andrey A. and Quinlan, Aaron R. and Sheffield, Nathan C. and Trynka, Gosia and Sandve, Geir K.},
	month = jul,
	year = {2018},
	pages = {W186--W193}
}

@article{bedtools,
	title = {{BEDTools}: a flexible suite of utilities for comparing genomic features},
	volume = {26},
	issn = {1367-4803},
	shorttitle = {{BEDTools}},
	doi = {10.1093/bioinformatics/btq033},
	abstract = {Abstract. Motivation: Testing for correlations between different sets of genomic features is a fundamental task in genomics research. However, searching for ov},
	language = {en},
	number = {6},
	journal = {Bioinformatics},
	author = {Quinlan, Aaron R. and Hall, Ira M.},
	month = mar,
	year = {2010},
	pages = {841--842}
}

@article{hyperbrowser,
	title = {The {Genomic} {HyperBrowser}: inferential genomics at the sequence level},
	volume = {11},
	issn = {1474-760X},
	shorttitle = {The {Genomic} {HyperBrowser}},
	doi = {10.1186/gb-2010-11-12-r121},
	abstract = {The immense increase in the generation of genomic scale data poses an unmet analytical challenge, due to a lack of established methodology with the required flexibility and power. We propose a first principled approach to statistical analysis of sequence-level genomic information. We provide a growing collection of generic biological investigations that query pairwise relations between tracks, represented as mathematical objects, along the genome. The Genomic HyperBrowser implements the approach and is available at http://hyperbrowser.uio.no.},
	number = {12},
	journal = {Genome Biology},
	author = {Sandve, Geir K. and Gundersen, Sveinung and Rydbeck, Halfdan and Glad, Ingrid K. and Holden, Lars and Holden, Marit and Liestøl, Knut and Clancy, Trevor and Ferkingstad, Egil and Johansen, Morten and Nygaard, Vegard and Tøstesen, Eivind and Frigessi, Arnoldo and Hovig, Eivind},
	month = dec,
	year = {2010},
	pages = {R121}
}

@article{levenshtein,
   author = {{Levenshtein}, V.~I.},
    title = "{Binary Codes Capable of Correcting Deletions, Insertions and Reversals}",
  journal = {Soviet Physics Doklady},
     year = 1966,
    month = feb,
   volume = 10,
    pages = {707--710},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@article{genelist,
    author = {Hsu, Fan and Clawson, Hiram and Diekhans, Mark and Kuhn, Robert M. and Kent, W. James and Haussler, David},
    title = "{The UCSC Known Genes}",
    journal = {Bioinformatics},
    volume = {22},
    number = {9},
    pages = {1036--1046},
    year = {2006},
    month = {02},
    abstract = "{The University of California Santa Cruz (UCSC) Known Genes dataset is constructed by a fully automated process, based on protein data from Swiss-Prot/TrEMBL (UniProt) and the associated mRNA data from Genbank. The detailed steps of this process are described. Extensive cross-references from this dataset to other genomic and proteomic data were constructed. For each known gene, a details page is provided containing rich information about the gene, together with extensive links to other relevant genomic, proteomic and pathway data. As of July 2005, the UCSC Known Genes are available for human, mouse and rat genomes. The Known Genes serves as a foundation to support several key programs: the Genome Browser, Proteome Browser, Gene Sorter and Table Browser offered at the UCSC website. All the associated data files and program source code are also available. They can be accessed at . The genomic coverage of UCSC Known Genes, RefSeq, Ensembl Genes, H-Invitational and CCDS is analyzed. Although UCSC Known Genes offers the highest genomic and CDS coverage among major human and mouse gene sets, more detailed analysis suggests all of them could be further improved.Contact:fanhsu@soe.ucsc.edu}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btl048},
    eprint = {http://oup.prod.sis.lan/bioinformatics/article-pdf/22/9/1036/509999/btl048.pdf},
}

